{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chuck Tingle Title Generator\n",
    "\n",
    "This notebook will generate Chuck Tingle titles using Tensorflow and LSTM. We will give the model an initial word or words, and the total number of words expected in the title. The LSTM will then generate the next word(s).\n",
    "\n",
    "\n",
    "Inspired by:\n",
    "https://towardsdatascience.com/simple-text-generation-using-lstm-deep-learning-d9ba808905ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vector/anaconda3/envs/KerasGPU2.2.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vector/anaconda3/envs/KerasGPU2.2.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vector/anaconda3/envs/KerasGPU2.2.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vector/anaconda3/envs/KerasGPU2.2.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vector/anaconda3/envs/KerasGPU2.2.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vector/anaconda3/envs/KerasGPU2.2.4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# load packages.\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    def __init__(self, input_data_file):\n",
    "        self.data = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.tokenizer = None\n",
    "        self.encoded_data = None\n",
    "        self.num_unique_words = None\n",
    "        self.max_len = None\n",
    "        self.sequences = None\n",
    "        self.num_data = None\n",
    "        self.input_data_file = input_data_file\n",
    "            \n",
    "    def load(self, column):\n",
    "        # reads in a file using pandas. Selects a column to be data\n",
    "        dataframe = pd.read_csv(self.input_data_file, error_bad_lines=False)\n",
    "        self.data = dataframe[column].values\n",
    "        \n",
    "    def encode(self):\n",
    "        # tokenizes the data\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.tokenizer.fit_on_texts(self.data)\n",
    "        self.encoded_data = self.tokenizer.texts_to_sequences(self.data)\n",
    "        self.num_unique_words = len(self.tokenizer.word_counts)+1\n",
    "        self.max_len = max([len(data) for data in self.encoded_data])\n",
    "\n",
    "    def generate_sequence(self):\n",
    "        # get list of outputs\n",
    "        seq_list = list()\n",
    "        for data_point in self.encoded_data:\n",
    "            for index in range(1, len(data_point)):\n",
    "                seq_list.append(data_point[:index+1])\n",
    "        # pad sequences\n",
    "        self.sequences = np.array(sequence.pad_sequences(seq_list, maxlen = self.max_len))    \n",
    "        self.num_data = len(self.sequences)\n",
    "        \n",
    "    def get_xy(self):\n",
    "        self.x = self.sequences[:,:-1]\n",
    "        # set the last word of the sequence as the y data\n",
    "        self.y = self.sequences[:,-1]\n",
    "        self.y = tf.keras.utils.to_categorical(self.sequences[:,-1], num_classes=self.num_unique_words)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file containing all book titles.\n",
    "\n",
    "data = Preprocessing('BookList.txt')\n",
    "data.load('title')\n",
    "data.encode()\n",
    "data.generate_sequence()\n",
    "data.get_xy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "class LSTM_model():\n",
    "    def __init__(self, params):\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.num_unique_words = params['num_unique_words']\n",
    "        self.max_len = params['max_len']\n",
    "        self.activation = params['activation']\n",
    "        self.optimizer = params['optimizer']\n",
    "        self.epochs = params['epochs']\n",
    "        self.metrics = params['metrics']\n",
    "        self.loss = params['loss']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.shuffle = params['shuffle']\n",
    "    \n",
    "    def built_model(self):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Embedding(self.num_unique_words, 16,input_length=self.max_len-1))\n",
    "        self.model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "        self.model.add(tf.keras.layers.Dropout(0.2))\n",
    "        self.model.add(tf.keras.layers.Dense(self.num_unique_words,activation=self.activation))\n",
    "        self.model.compile(loss=self.loss,optimizer=self.optimizer,metrics=self.metrics)\n",
    "\n",
    "    def train(self):\n",
    "        self.history = self.model.fit(self.x, self.y,\n",
    "                                      epochs = self.epochs,\n",
    "                                      shuffle = self.shuffle,\n",
    "                                      batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f938e4f2650>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f938e4f2d10>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "params = {\"activation\":\"softmax\",\n",
    "          \"epochs\":700,\n",
    "          \"loss\":\"categorical_crossentropy\",\n",
    "          \"optimizer\":tf.keras.optimizers.Adam(lr=1e-3),\n",
    "          \"metrics\":[\"accuracy\"],\n",
    "          \"num_unique_words\":data.num_unique_words,\n",
    "          \"max_len\":data.max_len,\n",
    "          \"batch_size\":512,\n",
    "          \"shuffle\":True}\n",
    "model_obj = LSTM_model(params)\n",
    "model_obj.x = data.x\n",
    "model_obj.y = data.y\n",
    "model_obj.built_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "2270/2270 [==============================] - 4s 2ms/sample - loss: 6.7390 - acc: 0.0330\n",
      "Epoch 2/700\n",
      "2270/2270 [==============================] - 1s 259us/sample - loss: 6.7215 - acc: 0.0744\n",
      "Epoch 3/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 6.6802 - acc: 0.0775\n",
      "Epoch 4/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 6.4988 - acc: 0.0780\n",
      "Epoch 5/700\n",
      "2270/2270 [==============================] - 1s 325us/sample - loss: 5.9039 - acc: 0.0700\n",
      "Epoch 6/700\n",
      "2270/2270 [==============================] - 1s 272us/sample - loss: 5.5005 - acc: 0.0705\n",
      "Epoch 7/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 5.3876 - acc: 0.0793\n",
      "Epoch 8/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 5.3849 - acc: 0.0780\n",
      "Epoch 9/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 5.3666 - acc: 0.0797\n",
      "Epoch 10/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 5.3404 - acc: 0.0749\n",
      "Epoch 11/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 5.3318 - acc: 0.0758\n",
      "Epoch 12/700\n",
      "2270/2270 [==============================] - 1s 253us/sample - loss: 5.3317 - acc: 0.0780\n",
      "Epoch 13/700\n",
      "2270/2270 [==============================] - 1s 319us/sample - loss: 5.3381 - acc: 0.0727\n",
      "Epoch 14/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 5.3307 - acc: 0.0789\n",
      "Epoch 15/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 5.3276 - acc: 0.0811\n",
      "Epoch 16/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 5.3217 - acc: 0.0784\n",
      "Epoch 17/700\n",
      "2270/2270 [==============================] - 1s 336us/sample - loss: 5.3261 - acc: 0.0802\n",
      "Epoch 18/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 5.3181 - acc: 0.0793\n",
      "Epoch 19/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 5.3244 - acc: 0.0802\n",
      "Epoch 20/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 5.3246 - acc: 0.0775\n",
      "Epoch 21/700\n",
      "2270/2270 [==============================] - 1s 259us/sample - loss: 5.3096 - acc: 0.0837\n",
      "Epoch 22/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 5.3140 - acc: 0.0780\n",
      "Epoch 23/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 5.3070 - acc: 0.0819\n",
      "Epoch 24/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 5.2999 - acc: 0.0784\n",
      "Epoch 25/700\n",
      "2270/2270 [==============================] - 1s 340us/sample - loss: 5.3014 - acc: 0.0855\n",
      "Epoch 26/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 5.2910 - acc: 0.0811\n",
      "Epoch 27/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 5.2853 - acc: 0.0815\n",
      "Epoch 28/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 5.2872 - acc: 0.0815\n",
      "Epoch 29/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 5.2812 - acc: 0.0797\n",
      "Epoch 30/700\n",
      "2270/2270 [==============================] - 1s 276us/sample - loss: 5.2717 - acc: 0.0846\n",
      "Epoch 31/700\n",
      "2270/2270 [==============================] - 1s 352us/sample - loss: 5.2677 - acc: 0.0828\n",
      "Epoch 32/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 5.2541 - acc: 0.0837\n",
      "Epoch 33/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 5.2493 - acc: 0.0828\n",
      "Epoch 34/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 5.2350 - acc: 0.0855\n",
      "Epoch 35/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 5.2195 - acc: 0.0841\n",
      "Epoch 36/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 5.2111 - acc: 0.0811\n",
      "Epoch 37/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 5.2105 - acc: 0.0850\n",
      "Epoch 38/700\n",
      "2270/2270 [==============================] - 1s 294us/sample - loss: 5.1913 - acc: 0.0850\n",
      "Epoch 39/700\n",
      "2270/2270 [==============================] - 1s 300us/sample - loss: 5.1672 - acc: 0.0850\n",
      "Epoch 40/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 5.1574 - acc: 0.0837\n",
      "Epoch 41/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 5.1326 - acc: 0.0868\n",
      "Epoch 42/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 5.1145 - acc: 0.0868\n",
      "Epoch 43/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 5.1008 - acc: 0.0868\n",
      "Epoch 44/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 5.0795 - acc: 0.0885\n",
      "Epoch 45/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 5.0610 - acc: 0.0802\n",
      "Epoch 46/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 5.0566 - acc: 0.0841\n",
      "Epoch 47/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 5.0341 - acc: 0.0872\n",
      "Epoch 48/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 5.0144 - acc: 0.0907\n",
      "Epoch 49/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 5.0125 - acc: 0.0863\n",
      "Epoch 50/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 5.0018 - acc: 0.0881\n",
      "Epoch 51/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 4.9841 - acc: 0.0987\n",
      "Epoch 52/700\n",
      "2270/2270 [==============================] - 1s 300us/sample - loss: 4.9633 - acc: 0.0943\n",
      "Epoch 53/700\n",
      "2270/2270 [==============================] - 1s 295us/sample - loss: 4.9376 - acc: 0.0947\n",
      "Epoch 54/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 4.9304 - acc: 0.1066\n",
      "Epoch 55/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 4.9111 - acc: 0.1181\n",
      "Epoch 56/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 4.8939 - acc: 0.1048\n",
      "Epoch 57/700\n",
      "2270/2270 [==============================] - 1s 261us/sample - loss: 4.8809 - acc: 0.1194\n",
      "Epoch 58/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 4.8676 - acc: 0.1269\n",
      "Epoch 59/700\n",
      "2270/2270 [==============================] - 1s 267us/sample - loss: 4.8647 - acc: 0.1256\n",
      "Epoch 60/700\n",
      "2270/2270 [==============================] - 1s 323us/sample - loss: 4.8932 - acc: 0.1352\n",
      "Epoch 61/700\n",
      "2270/2270 [==============================] - 1s 239us/sample - loss: 4.8777 - acc: 0.1357\n",
      "Epoch 62/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 4.8547 - acc: 0.1366\n",
      "Epoch 63/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 4.8242 - acc: 0.1317\n",
      "Epoch 64/700\n",
      "2270/2270 [==============================] - 1s 252us/sample - loss: 4.7993 - acc: 0.1388\n",
      "Epoch 65/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 4.7685 - acc: 0.1427\n",
      "Epoch 66/700\n",
      "2270/2270 [==============================] - 1s 263us/sample - loss: 4.7357 - acc: 0.1463\n",
      "Epoch 67/700\n",
      "2270/2270 [==============================] - 1s 328us/sample - loss: 4.7238 - acc: 0.1463\n",
      "Epoch 68/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 4.6985 - acc: 0.1502\n",
      "Epoch 69/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 4.6703 - acc: 0.1445\n",
      "Epoch 70/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 4.6421 - acc: 0.1507\n",
      "Epoch 71/700\n",
      "2270/2270 [==============================] - 1s 270us/sample - loss: 4.6319 - acc: 0.1520\n",
      "Epoch 72/700\n",
      "2270/2270 [==============================] - 1s 243us/sample - loss: 4.6076 - acc: 0.1537\n",
      "Epoch 73/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 4.5815 - acc: 0.1617\n",
      "Epoch 74/700\n",
      "2270/2270 [==============================] - 1s 336us/sample - loss: 4.5613 - acc: 0.1617\n",
      "Epoch 75/700\n",
      "2270/2270 [==============================] - 1s 277us/sample - loss: 4.5551 - acc: 0.1648\n",
      "Epoch 76/700\n",
      "2270/2270 [==============================] - 1s 220us/sample - loss: 4.5296 - acc: 0.1683\n",
      "Epoch 77/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 4.5175 - acc: 0.1731\n",
      "Epoch 78/700\n",
      "2270/2270 [==============================] - 1s 276us/sample - loss: 4.4950 - acc: 0.1718\n",
      "Epoch 79/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 4.4784 - acc: 0.1700\n",
      "Epoch 80/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 1s 240us/sample - loss: 4.4569 - acc: 0.1722\n",
      "Epoch 81/700\n",
      "2270/2270 [==============================] - 1s 375us/sample - loss: 4.4447 - acc: 0.1863\n",
      "Epoch 82/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 4.4273 - acc: 0.1846\n",
      "Epoch 83/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 4.4213 - acc: 0.1846\n",
      "Epoch 84/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 4.3950 - acc: 0.1877\n",
      "Epoch 85/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 4.3825 - acc: 0.1899\n",
      "Epoch 86/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 4.3705 - acc: 0.1903\n",
      "Epoch 87/700\n",
      "2270/2270 [==============================] - 1s 351us/sample - loss: 4.3483 - acc: 0.1987\n",
      "Epoch 88/700\n",
      "2270/2270 [==============================] - 1s 277us/sample - loss: 4.3325 - acc: 0.1947\n",
      "Epoch 89/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 4.3079 - acc: 0.1987\n",
      "Epoch 90/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 4.2998 - acc: 0.2004\n",
      "Epoch 91/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 4.2778 - acc: 0.2000\n",
      "Epoch 92/700\n",
      "2270/2270 [==============================] - 1s 265us/sample - loss: 4.2651 - acc: 0.2040\n",
      "Epoch 93/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 4.2479 - acc: 0.2132\n",
      "Epoch 94/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 4.2330 - acc: 0.2097\n",
      "Epoch 95/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 4.2286 - acc: 0.2172\n",
      "Epoch 96/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 4.2117 - acc: 0.2150\n",
      "Epoch 97/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 4.2006 - acc: 0.2198\n",
      "Epoch 98/700\n",
      "2270/2270 [==============================] - 1s 250us/sample - loss: 4.1783 - acc: 0.2220\n",
      "Epoch 99/700\n",
      "2270/2270 [==============================] - 1s 343us/sample - loss: 4.1740 - acc: 0.2189\n",
      "Epoch 100/700\n",
      "2270/2270 [==============================] - 1s 272us/sample - loss: 4.1597 - acc: 0.2220\n",
      "Epoch 101/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 4.1700 - acc: 0.2256\n",
      "Epoch 102/700\n",
      "2270/2270 [==============================] - 1s 253us/sample - loss: 4.1867 - acc: 0.2185\n",
      "Epoch 103/700\n",
      "2270/2270 [==============================] - 1s 249us/sample - loss: 4.1954 - acc: 0.2304\n",
      "Epoch 104/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 4.1704 - acc: 0.2304\n",
      "Epoch 105/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 4.1489 - acc: 0.2352\n",
      "Epoch 106/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 4.1244 - acc: 0.2326\n",
      "Epoch 107/700\n",
      "2270/2270 [==============================] - 1s 345us/sample - loss: 4.0870 - acc: 0.2383\n",
      "Epoch 108/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 4.0637 - acc: 0.2361\n",
      "Epoch 109/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 4.0444 - acc: 0.2423\n",
      "Epoch 110/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 4.0259 - acc: 0.2432\n",
      "Epoch 111/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 4.0076 - acc: 0.2388\n",
      "Epoch 112/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 3.9828 - acc: 0.2476\n",
      "Epoch 113/700\n",
      "2270/2270 [==============================] - 1s 278us/sample - loss: 3.9832 - acc: 0.2463\n",
      "Epoch 114/700\n",
      "2270/2270 [==============================] - 1s 329us/sample - loss: 3.9701 - acc: 0.2427\n",
      "Epoch 115/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 3.9417 - acc: 0.2463\n",
      "Epoch 116/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 3.9367 - acc: 0.2507\n",
      "Epoch 117/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 3.9315 - acc: 0.2577\n",
      "Epoch 118/700\n",
      "2270/2270 [==============================] - 1s 260us/sample - loss: 3.9209 - acc: 0.2546\n",
      "Epoch 119/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 3.9124 - acc: 0.2573\n",
      "Epoch 120/700\n",
      "2270/2270 [==============================] - 1s 296us/sample - loss: 3.8904 - acc: 0.2581\n",
      "Epoch 121/700\n",
      "2270/2270 [==============================] - 1s 330us/sample - loss: 3.9118 - acc: 0.2608\n",
      "Epoch 122/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 3.9224 - acc: 0.2687\n",
      "Epoch 123/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 3.9143 - acc: 0.2670\n",
      "Epoch 124/700\n",
      "2270/2270 [==============================] - 1s 252us/sample - loss: 3.9059 - acc: 0.2665\n",
      "Epoch 125/700\n",
      "2270/2270 [==============================] - 1s 243us/sample - loss: 3.8844 - acc: 0.2736\n",
      "Epoch 126/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 3.8640 - acc: 0.2674\n",
      "Epoch 127/700\n",
      "2270/2270 [==============================] - 1s 284us/sample - loss: 3.8359 - acc: 0.2780\n",
      "Epoch 128/700\n",
      "2270/2270 [==============================] - 1s 349us/sample - loss: 3.8193 - acc: 0.2705\n",
      "Epoch 129/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 3.7919 - acc: 0.2811\n",
      "Epoch 130/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 3.7767 - acc: 0.2837\n",
      "Epoch 131/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 3.7632 - acc: 0.2753\n",
      "Epoch 132/700\n",
      "2270/2270 [==============================] - 1s 256us/sample - loss: 3.7411 - acc: 0.2872\n",
      "Epoch 133/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 3.7283 - acc: 0.2872\n",
      "Epoch 134/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 3.7111 - acc: 0.2903\n",
      "Epoch 135/700\n",
      "2270/2270 [==============================] - 1s 319us/sample - loss: 3.7061 - acc: 0.2894\n",
      "Epoch 136/700\n",
      "2270/2270 [==============================] - 1s 305us/sample - loss: 3.6852 - acc: 0.2833\n",
      "Epoch 137/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 3.6876 - acc: 0.2859\n",
      "Epoch 138/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 3.6633 - acc: 0.2943\n",
      "Epoch 139/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 3.6527 - acc: 0.2952\n",
      "Epoch 140/700\n",
      "2270/2270 [==============================] - 1s 255us/sample - loss: 3.6410 - acc: 0.2912\n",
      "Epoch 141/700\n",
      "2270/2270 [==============================] - 1s 242us/sample - loss: 3.7148 - acc: 0.2956\n",
      "Epoch 142/700\n",
      "2270/2270 [==============================] - 1s 281us/sample - loss: 3.9487 - acc: 0.2965\n",
      "Epoch 143/700\n",
      "2270/2270 [==============================] - 1s 336us/sample - loss: 3.9542 - acc: 0.2947\n",
      "Epoch 144/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 3.8756 - acc: 0.2991\n",
      "Epoch 145/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 3.8030 - acc: 0.2965\n",
      "Epoch 146/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 3.7568 - acc: 0.3031\n",
      "Epoch 147/700\n",
      "2270/2270 [==============================] - 1s 259us/sample - loss: 3.6855 - acc: 0.2956\n",
      "Epoch 148/700\n",
      "2270/2270 [==============================] - 1s 239us/sample - loss: 3.6457 - acc: 0.2974\n",
      "Epoch 149/700\n",
      "2270/2270 [==============================] - 1s 265us/sample - loss: 3.7343 - acc: 0.2996\n",
      "Epoch 150/700\n",
      "2270/2270 [==============================] - 1s 319us/sample - loss: 3.7638 - acc: 0.3000\n",
      "Epoch 151/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 3.7414 - acc: 0.3000\n",
      "Epoch 152/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 3.7166 - acc: 0.3066\n",
      "Epoch 153/700\n",
      "2270/2270 [==============================] - 1s 249us/sample - loss: 3.6821 - acc: 0.3110\n",
      "Epoch 154/700\n",
      "2270/2270 [==============================] - 1s 266us/sample - loss: 3.6566 - acc: 0.3070\n",
      "Epoch 155/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 3.6283 - acc: 0.3057\n",
      "Epoch 156/700\n",
      "2270/2270 [==============================] - 1s 260us/sample - loss: 3.6001 - acc: 0.3145\n",
      "Epoch 157/700\n",
      "2270/2270 [==============================] - 1s 348us/sample - loss: 3.5770 - acc: 0.3070\n",
      "Epoch 158/700\n",
      "2270/2270 [==============================] - 1s 279us/sample - loss: 3.5605 - acc: 0.3119\n",
      "Epoch 159/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 1s 225us/sample - loss: 3.5312 - acc: 0.3119\n",
      "Epoch 160/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 3.5142 - acc: 0.3150\n",
      "Epoch 161/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 3.4997 - acc: 0.3057\n",
      "Epoch 162/700\n",
      "2270/2270 [==============================] - 1s 261us/sample - loss: 3.4751 - acc: 0.3115\n",
      "Epoch 163/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 3.4482 - acc: 0.3172\n",
      "Epoch 164/700\n",
      "2270/2270 [==============================] - 1s 249us/sample - loss: 3.4413 - acc: 0.3154\n",
      "Epoch 165/700\n",
      "2270/2270 [==============================] - 1s 390us/sample - loss: 3.4192 - acc: 0.3159\n",
      "Epoch 166/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 3.4038 - acc: 0.3137\n",
      "Epoch 167/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 3.3851 - acc: 0.3150\n",
      "Epoch 168/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 3.3745 - acc: 0.3216\n",
      "Epoch 169/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 3.3557 - acc: 0.3242\n",
      "Epoch 170/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 3.3506 - acc: 0.3176\n",
      "Epoch 171/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 3.3344 - acc: 0.3247\n",
      "Epoch 172/700\n",
      "2270/2270 [==============================] - 1s 258us/sample - loss: 3.3105 - acc: 0.3242\n",
      "Epoch 173/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 3.3127 - acc: 0.3203\n",
      "Epoch 174/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 3.2887 - acc: 0.3225\n",
      "Epoch 175/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 3.2803 - acc: 0.3300\n",
      "Epoch 176/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 3.2550 - acc: 0.3251\n",
      "Epoch 177/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 3.2585 - acc: 0.3317\n",
      "Epoch 178/700\n",
      "2270/2270 [==============================] - 0s 209us/sample - loss: 3.2501 - acc: 0.3260\n",
      "Epoch 179/700\n",
      "2270/2270 [==============================] - 0s 199us/sample - loss: 3.2312 - acc: 0.3361\n",
      "Epoch 180/700\n",
      "2270/2270 [==============================] - 0s 211us/sample - loss: 3.2110 - acc: 0.3352\n",
      "Epoch 181/700\n",
      "2270/2270 [==============================] - 0s 207us/sample - loss: 3.2031 - acc: 0.3383\n",
      "Epoch 182/700\n",
      "2270/2270 [==============================] - 0s 198us/sample - loss: 3.1958 - acc: 0.3300\n",
      "Epoch 183/700\n",
      "2270/2270 [==============================] - 1s 220us/sample - loss: 3.1902 - acc: 0.3282\n",
      "Epoch 184/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 3.1598 - acc: 0.3414\n",
      "Epoch 185/700\n",
      "2270/2270 [==============================] - 1s 351us/sample - loss: 3.1653 - acc: 0.3322\n",
      "Epoch 186/700\n",
      "2270/2270 [==============================] - 1s 252us/sample - loss: 3.1358 - acc: 0.3383\n",
      "Epoch 187/700\n",
      "2270/2270 [==============================] - 0s 220us/sample - loss: 3.1342 - acc: 0.3458\n",
      "Epoch 188/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 3.1271 - acc: 0.3370\n",
      "Epoch 189/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 3.1142 - acc: 0.3493\n",
      "Epoch 190/700\n",
      "2270/2270 [==============================] - 1s 258us/sample - loss: 3.1008 - acc: 0.3427\n",
      "Epoch 191/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 3.0801 - acc: 0.3533\n",
      "Epoch 192/700\n",
      "2270/2270 [==============================] - 1s 260us/sample - loss: 3.0683 - acc: 0.3515\n",
      "Epoch 193/700\n",
      "2270/2270 [==============================] - 1s 300us/sample - loss: 3.0671 - acc: 0.3489\n",
      "Epoch 194/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 3.0515 - acc: 0.3467\n",
      "Epoch 195/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 3.0415 - acc: 0.3507\n",
      "Epoch 196/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 3.0430 - acc: 0.3559\n",
      "Epoch 197/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 3.0206 - acc: 0.3604\n",
      "Epoch 198/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 3.0081 - acc: 0.3656\n",
      "Epoch 199/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 2.9944 - acc: 0.3577\n",
      "Epoch 200/700\n",
      "2270/2270 [==============================] - 1s 274us/sample - loss: 2.9847 - acc: 0.3612\n",
      "Epoch 201/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.9645 - acc: 0.3678\n",
      "Epoch 202/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 2.9662 - acc: 0.3581\n",
      "Epoch 203/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 2.9646 - acc: 0.3692\n",
      "Epoch 204/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 2.9508 - acc: 0.3626\n",
      "Epoch 205/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 2.9426 - acc: 0.3630\n",
      "Epoch 206/700\n",
      "2270/2270 [==============================] - 1s 284us/sample - loss: 2.9190 - acc: 0.3656\n",
      "Epoch 207/700\n",
      "2270/2270 [==============================] - 1s 322us/sample - loss: 2.9224 - acc: 0.3762\n",
      "Epoch 208/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 2.8976 - acc: 0.3709\n",
      "Epoch 209/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 2.8889 - acc: 0.3731\n",
      "Epoch 210/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 2.8827 - acc: 0.3722\n",
      "Epoch 211/700\n",
      "2270/2270 [==============================] - 1s 279us/sample - loss: 2.8822 - acc: 0.3784\n",
      "Epoch 212/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 2.8612 - acc: 0.3819\n",
      "Epoch 213/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.8448 - acc: 0.3819\n",
      "Epoch 214/700\n",
      "2270/2270 [==============================] - 1s 356us/sample - loss: 2.8455 - acc: 0.3771\n",
      "Epoch 215/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 2.8370 - acc: 0.3811\n",
      "Epoch 216/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 2.8208 - acc: 0.3833\n",
      "Epoch 217/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.8214 - acc: 0.3789\n",
      "Epoch 218/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 2.8118 - acc: 0.3868\n",
      "Epoch 219/700\n",
      "2270/2270 [==============================] - 1s 252us/sample - loss: 2.7985 - acc: 0.3890\n",
      "Epoch 220/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 2.7893 - acc: 0.3899\n",
      "Epoch 221/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 2.7749 - acc: 0.4026\n",
      "Epoch 222/700\n",
      "2270/2270 [==============================] - 1s 352us/sample - loss: 2.7675 - acc: 0.3952\n",
      "Epoch 223/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 2.7698 - acc: 0.3938\n",
      "Epoch 224/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 2.7596 - acc: 0.3987\n",
      "Epoch 225/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 2.7350 - acc: 0.3903\n",
      "Epoch 226/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.7263 - acc: 0.4000\n",
      "Epoch 227/700\n",
      "2270/2270 [==============================] - 1s 253us/sample - loss: 2.7172 - acc: 0.4022\n",
      "Epoch 228/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.7117 - acc: 0.4048\n",
      "Epoch 229/700\n",
      "2270/2270 [==============================] - 1s 277us/sample - loss: 2.6921 - acc: 0.4075\n",
      "Epoch 230/700\n",
      "2270/2270 [==============================] - 1s 345us/sample - loss: 2.6929 - acc: 0.4000\n",
      "Epoch 231/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 2.6810 - acc: 0.4159\n",
      "Epoch 232/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 2.6757 - acc: 0.4070\n",
      "Epoch 233/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 2.6676 - acc: 0.4110\n",
      "Epoch 234/700\n",
      "2270/2270 [==============================] - 1s 261us/sample - loss: 2.6397 - acc: 0.4172\n",
      "Epoch 235/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 2.6401 - acc: 0.4216\n",
      "Epoch 236/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 2.6415 - acc: 0.4088\n",
      "Epoch 237/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 1s 373us/sample - loss: 2.6369 - acc: 0.4189\n",
      "Epoch 238/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 2.6295 - acc: 0.4251\n",
      "Epoch 239/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 2.6164 - acc: 0.4159\n",
      "Epoch 240/700\n",
      "2270/2270 [==============================] - 1s 249us/sample - loss: 2.6075 - acc: 0.4256\n",
      "Epoch 241/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 2.5764 - acc: 0.4330\n",
      "Epoch 242/700\n",
      "2270/2270 [==============================] - 0s 220us/sample - loss: 2.5877 - acc: 0.4220\n",
      "Epoch 243/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 2.5727 - acc: 0.4317\n",
      "Epoch 244/700\n",
      "2270/2270 [==============================] - 1s 239us/sample - loss: 2.5638 - acc: 0.4410\n",
      "Epoch 245/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 2.5499 - acc: 0.4300\n",
      "Epoch 246/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 2.5434 - acc: 0.4388\n",
      "Epoch 247/700\n",
      "2270/2270 [==============================] - 0s 202us/sample - loss: 2.5361 - acc: 0.4348\n",
      "Epoch 248/700\n",
      "2270/2270 [==============================] - 0s 204us/sample - loss: 2.5257 - acc: 0.4432\n",
      "Epoch 249/700\n",
      "2270/2270 [==============================] - 0s 202us/sample - loss: 2.5312 - acc: 0.4436\n",
      "Epoch 250/700\n",
      "2270/2270 [==============================] - 0s 202us/sample - loss: 2.5034 - acc: 0.4427\n",
      "Epoch 251/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 2.4980 - acc: 0.4515\n",
      "Epoch 252/700\n",
      "2270/2270 [==============================] - 0s 214us/sample - loss: 2.4916 - acc: 0.4507\n",
      "Epoch 253/700\n",
      "2270/2270 [==============================] - 0s 203us/sample - loss: 2.4769 - acc: 0.4559\n",
      "Epoch 254/700\n",
      "2270/2270 [==============================] - 0s 204us/sample - loss: 2.4693 - acc: 0.4555\n",
      "Epoch 255/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 2.4660 - acc: 0.4590\n",
      "Epoch 256/700\n",
      "2270/2270 [==============================] - 0s 211us/sample - loss: 2.4577 - acc: 0.4533\n",
      "Epoch 257/700\n",
      "2270/2270 [==============================] - 0s 210us/sample - loss: 2.4467 - acc: 0.4639\n",
      "Epoch 258/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 2.4418 - acc: 0.4639\n",
      "Epoch 259/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 2.4227 - acc: 0.4687\n",
      "Epoch 260/700\n",
      "2270/2270 [==============================] - 1s 255us/sample - loss: 2.4198 - acc: 0.4617\n",
      "Epoch 261/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 2.4137 - acc: 0.4705\n",
      "Epoch 262/700\n",
      "2270/2270 [==============================] - 1s 309us/sample - loss: 2.4100 - acc: 0.4749\n",
      "Epoch 263/700\n",
      "2270/2270 [==============================] - 1s 316us/sample - loss: 2.4025 - acc: 0.4744\n",
      "Epoch 264/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 2.3928 - acc: 0.4749\n",
      "Epoch 265/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 2.3881 - acc: 0.4815\n",
      "Epoch 266/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 2.3713 - acc: 0.4819\n",
      "Epoch 267/700\n",
      "2270/2270 [==============================] - 1s 275us/sample - loss: 2.3762 - acc: 0.4907\n",
      "Epoch 268/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 2.3672 - acc: 0.4828\n",
      "Epoch 269/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 2.3514 - acc: 0.4846\n",
      "Epoch 270/700\n",
      "2270/2270 [==============================] - 1s 379us/sample - loss: 2.3240 - acc: 0.4846\n",
      "Epoch 271/700\n",
      "2270/2270 [==============================] - 1s 265us/sample - loss: 2.3418 - acc: 0.4833\n",
      "Epoch 272/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 2.3401 - acc: 0.4925\n",
      "Epoch 273/700\n",
      "2270/2270 [==============================] - 1s 251us/sample - loss: 2.3158 - acc: 0.4952\n",
      "Epoch 274/700\n",
      "2270/2270 [==============================] - 1s 251us/sample - loss: 2.3154 - acc: 0.4925\n",
      "Epoch 275/700\n",
      "2270/2270 [==============================] - 1s 268us/sample - loss: 2.3016 - acc: 0.4916\n",
      "Epoch 276/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 2.3008 - acc: 0.4925\n",
      "Epoch 277/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 2.2850 - acc: 0.4952\n",
      "Epoch 278/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 2.2831 - acc: 0.5040\n",
      "Epoch 279/700\n",
      "2270/2270 [==============================] - 1s 339us/sample - loss: 2.2798 - acc: 0.4974\n",
      "Epoch 280/700\n",
      "2270/2270 [==============================] - 1s 275us/sample - loss: 2.2474 - acc: 0.5123\n",
      "Epoch 281/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 2.2662 - acc: 0.5070\n",
      "Epoch 282/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 2.2639 - acc: 0.5053\n",
      "Epoch 283/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 2.2314 - acc: 0.5000\n",
      "Epoch 284/700\n",
      "2270/2270 [==============================] - 1s 261us/sample - loss: 2.2269 - acc: 0.5119\n",
      "Epoch 285/700\n",
      "2270/2270 [==============================] - 1s 265us/sample - loss: 2.2189 - acc: 0.5176\n",
      "Epoch 286/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 2.2081 - acc: 0.5088\n",
      "Epoch 287/700\n",
      "2270/2270 [==============================] - 1s 301us/sample - loss: 2.2039 - acc: 0.5159\n",
      "Epoch 288/700\n",
      "2270/2270 [==============================] - 1s 300us/sample - loss: 2.1951 - acc: 0.5181\n",
      "Epoch 289/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 2.1832 - acc: 0.5260\n",
      "Epoch 290/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 2.1736 - acc: 0.5229\n",
      "Epoch 291/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 2.1654 - acc: 0.5251\n",
      "Epoch 292/700\n",
      "2270/2270 [==============================] - 1s 255us/sample - loss: 2.1680 - acc: 0.5251\n",
      "Epoch 293/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 2.1586 - acc: 0.5282\n",
      "Epoch 294/700\n",
      "2270/2270 [==============================] - 1s 261us/sample - loss: 2.1524 - acc: 0.5317\n",
      "Epoch 295/700\n",
      "2270/2270 [==============================] - 1s 342us/sample - loss: 2.1442 - acc: 0.5366\n",
      "Epoch 296/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 2.1304 - acc: 0.5392\n",
      "Epoch 297/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.1307 - acc: 0.5370\n",
      "Epoch 298/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 2.1140 - acc: 0.5419\n",
      "Epoch 299/700\n",
      "2270/2270 [==============================] - 1s 259us/sample - loss: 2.1100 - acc: 0.5401\n",
      "Epoch 300/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 2.1018 - acc: 0.5414\n",
      "Epoch 301/700\n",
      "2270/2270 [==============================] - 1s 384us/sample - loss: 2.0863 - acc: 0.5480\n",
      "Epoch 302/700\n",
      "2270/2270 [==============================] - 1s 258us/sample - loss: 2.0943 - acc: 0.5449\n",
      "Epoch 303/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 2.0771 - acc: 0.5454\n",
      "Epoch 304/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 2.0772 - acc: 0.5458\n",
      "Epoch 305/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 2.0623 - acc: 0.5555\n",
      "Epoch 306/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 2.0670 - acc: 0.5520\n",
      "Epoch 307/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 2.0542 - acc: 0.5511\n",
      "Epoch 308/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 2.0476 - acc: 0.5590\n",
      "Epoch 309/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 2.0424 - acc: 0.5529\n",
      "Epoch 310/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 2.0231 - acc: 0.5612\n",
      "Epoch 311/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 2.0168 - acc: 0.5767\n",
      "Epoch 312/700\n",
      "2270/2270 [==============================] - 1s 264us/sample - loss: 2.0158 - acc: 0.5581\n",
      "Epoch 313/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 2.0166 - acc: 0.5670\n",
      "Epoch 314/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 2.0041 - acc: 0.5692\n",
      "Epoch 315/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 1s 277us/sample - loss: 1.9988 - acc: 0.5705\n",
      "Epoch 316/700\n",
      "2270/2270 [==============================] - 1s 304us/sample - loss: 1.9972 - acc: 0.5740\n",
      "Epoch 317/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 1.9827 - acc: 0.5705\n",
      "Epoch 318/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.9710 - acc: 0.5811\n",
      "Epoch 319/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.9704 - acc: 0.5709\n",
      "Epoch 320/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.9657 - acc: 0.5696\n",
      "Epoch 321/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 1.9654 - acc: 0.5811\n",
      "Epoch 322/700\n",
      "2270/2270 [==============================] - 1s 243us/sample - loss: 1.9420 - acc: 0.5921\n",
      "Epoch 323/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.9415 - acc: 0.5828\n",
      "Epoch 324/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 1.9232 - acc: 0.5960\n",
      "Epoch 325/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.9258 - acc: 0.5868\n",
      "Epoch 326/700\n",
      "2270/2270 [==============================] - 1s 385us/sample - loss: 1.9106 - acc: 0.5859\n",
      "Epoch 327/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.9317 - acc: 0.5912\n",
      "Epoch 328/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.8989 - acc: 0.5921\n",
      "Epoch 329/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.8952 - acc: 0.5943\n",
      "Epoch 330/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 1.8926 - acc: 0.6084\n",
      "Epoch 331/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 1.8894 - acc: 0.6026\n",
      "Epoch 332/700\n",
      "2270/2270 [==============================] - 0s 211us/sample - loss: 1.8826 - acc: 0.5969\n",
      "Epoch 333/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.8767 - acc: 0.5965\n",
      "Epoch 334/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.8694 - acc: 0.5987\n",
      "Epoch 335/700\n",
      "2270/2270 [==============================] - 1s 250us/sample - loss: 1.8627 - acc: 0.6035\n",
      "Epoch 336/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.8480 - acc: 0.5978\n",
      "Epoch 337/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 1.8456 - acc: 0.6031\n",
      "Epoch 338/700\n",
      "2270/2270 [==============================] - 1s 329us/sample - loss: 1.8498 - acc: 0.6026\n",
      "Epoch 339/700\n",
      "2270/2270 [==============================] - 1s 292us/sample - loss: 1.8252 - acc: 0.6163\n",
      "Epoch 340/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.8148 - acc: 0.6159\n",
      "Epoch 341/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.8244 - acc: 0.6132\n",
      "Epoch 342/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 1.8210 - acc: 0.6026\n",
      "Epoch 343/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 1.8138 - acc: 0.6189\n",
      "Epoch 344/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 1.8021 - acc: 0.6194\n",
      "Epoch 345/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 1.7929 - acc: 0.6132\n",
      "Epoch 346/700\n",
      "2270/2270 [==============================] - 1s 369us/sample - loss: 1.7972 - acc: 0.6150\n",
      "Epoch 347/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 1.7690 - acc: 0.6194\n",
      "Epoch 348/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 1.7612 - acc: 0.6308\n",
      "Epoch 349/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.7650 - acc: 0.6242\n",
      "Epoch 350/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 1.7609 - acc: 0.6225\n",
      "Epoch 351/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.7533 - acc: 0.6326\n",
      "Epoch 352/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.7735 - acc: 0.6198\n",
      "Epoch 353/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 1.7434 - acc: 0.6339\n",
      "Epoch 354/700\n",
      "2270/2270 [==============================] - 1s 272us/sample - loss: 1.7302 - acc: 0.6291\n",
      "Epoch 355/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 1.7405 - acc: 0.6295\n",
      "Epoch 356/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 1.7128 - acc: 0.6383\n",
      "Epoch 357/700\n",
      "2270/2270 [==============================] - 1s 356us/sample - loss: 1.7109 - acc: 0.6370\n",
      "Epoch 358/700\n",
      "2270/2270 [==============================] - 1s 242us/sample - loss: 1.7144 - acc: 0.6423\n",
      "Epoch 359/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.7172 - acc: 0.6352\n",
      "Epoch 360/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.7022 - acc: 0.6542\n",
      "Epoch 361/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.7015 - acc: 0.6414\n",
      "Epoch 362/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 1.6861 - acc: 0.6436\n",
      "Epoch 363/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.6875 - acc: 0.6423\n",
      "Epoch 364/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 1.6769 - acc: 0.6441\n",
      "Epoch 365/700\n",
      "2270/2270 [==============================] - 1s 325us/sample - loss: 1.6831 - acc: 0.6436\n",
      "Epoch 366/700\n",
      "2270/2270 [==============================] - 1s 280us/sample - loss: 1.6745 - acc: 0.6441\n",
      "Epoch 367/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.6777 - acc: 0.6374\n",
      "Epoch 368/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.6458 - acc: 0.6449\n",
      "Epoch 369/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 1.6457 - acc: 0.6546\n",
      "Epoch 370/700\n",
      "2270/2270 [==============================] - 1s 256us/sample - loss: 1.6561 - acc: 0.6498\n",
      "Epoch 371/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 1.6304 - acc: 0.6626\n",
      "Epoch 372/700\n",
      "2270/2270 [==============================] - 0s 210us/sample - loss: 1.6395 - acc: 0.6520\n",
      "Epoch 373/700\n",
      "2270/2270 [==============================] - 1s 285us/sample - loss: 1.6336 - acc: 0.6529\n",
      "Epoch 374/700\n",
      "2270/2270 [==============================] - 1s 321us/sample - loss: 1.6139 - acc: 0.6581\n",
      "Epoch 375/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.6236 - acc: 0.6705\n",
      "Epoch 376/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.6234 - acc: 0.6507\n",
      "Epoch 377/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.6046 - acc: 0.6595\n",
      "Epoch 378/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 1.6115 - acc: 0.6656\n",
      "Epoch 379/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.6058 - acc: 0.6537\n",
      "Epoch 380/700\n",
      "2270/2270 [==============================] - 1s 295us/sample - loss: 1.5829 - acc: 0.6749\n",
      "Epoch 381/700\n",
      "2270/2270 [==============================] - 1s 330us/sample - loss: 1.5893 - acc: 0.6674\n",
      "Epoch 382/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.5730 - acc: 0.6722\n",
      "Epoch 383/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.5702 - acc: 0.6780\n",
      "Epoch 384/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 1.5674 - acc: 0.6780\n",
      "Epoch 385/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.5730 - acc: 0.6687\n",
      "Epoch 386/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.5544 - acc: 0.6696\n",
      "Epoch 387/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.5476 - acc: 0.6819\n",
      "Epoch 388/700\n",
      "2270/2270 [==============================] - 0s 215us/sample - loss: 1.5571 - acc: 0.6762\n",
      "Epoch 389/700\n",
      "2270/2270 [==============================] - 0s 216us/sample - loss: 1.5378 - acc: 0.6850\n",
      "Epoch 390/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 1.5349 - acc: 0.6731\n",
      "Epoch 391/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 1.5188 - acc: 0.6903\n",
      "Epoch 392/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 1.5152 - acc: 0.6894\n",
      "Epoch 393/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 0s 213us/sample - loss: 1.5268 - acc: 0.6828\n",
      "Epoch 394/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.5116 - acc: 0.6855\n",
      "Epoch 395/700\n",
      "2270/2270 [==============================] - 0s 208us/sample - loss: 1.5185 - acc: 0.6855\n",
      "Epoch 396/700\n",
      "2270/2270 [==============================] - 0s 205us/sample - loss: 1.5036 - acc: 0.6872\n",
      "Epoch 397/700\n",
      "2270/2270 [==============================] - 0s 209us/sample - loss: 1.5057 - acc: 0.6903\n",
      "Epoch 398/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.4952 - acc: 0.6868\n",
      "Epoch 399/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.4859 - acc: 0.6969\n",
      "Epoch 400/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 1.4879 - acc: 0.6930\n",
      "Epoch 401/700\n",
      "2270/2270 [==============================] - 1s 255us/sample - loss: 1.4738 - acc: 0.6833\n",
      "Epoch 402/700\n",
      "2270/2270 [==============================] - 1s 363us/sample - loss: 1.4542 - acc: 0.6903\n",
      "Epoch 403/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 1.4674 - acc: 0.6912\n",
      "Epoch 404/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.4588 - acc: 0.6921\n",
      "Epoch 405/700\n",
      "2270/2270 [==============================] - 0s 215us/sample - loss: 1.4553 - acc: 0.6996\n",
      "Epoch 406/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 1.4530 - acc: 0.6960\n",
      "Epoch 407/700\n",
      "2270/2270 [==============================] - 1s 276us/sample - loss: 1.4462 - acc: 0.6996\n",
      "Epoch 408/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 1.4478 - acc: 0.6947\n",
      "Epoch 409/700\n",
      "2270/2270 [==============================] - 1s 275us/sample - loss: 1.4382 - acc: 0.6841\n",
      "Epoch 410/700\n",
      "2270/2270 [==============================] - 1s 349us/sample - loss: 1.4230 - acc: 0.7079\n",
      "Epoch 411/700\n",
      "2270/2270 [==============================] - 1s 271us/sample - loss: 1.4273 - acc: 0.7013\n",
      "Epoch 412/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.4307 - acc: 0.7013\n",
      "Epoch 413/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 1.4208 - acc: 0.7123\n",
      "Epoch 414/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.4129 - acc: 0.7057\n",
      "Epoch 415/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.4024 - acc: 0.7026\n",
      "Epoch 416/700\n",
      "2270/2270 [==============================] - 1s 262us/sample - loss: 1.4199 - acc: 0.7040\n",
      "Epoch 417/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.3952 - acc: 0.7084\n",
      "Epoch 418/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.3913 - acc: 0.7137\n",
      "Epoch 419/700\n",
      "2270/2270 [==============================] - 1s 301us/sample - loss: 1.3999 - acc: 0.7141\n",
      "Epoch 420/700\n",
      "2270/2270 [==============================] - 1s 294us/sample - loss: 1.4032 - acc: 0.6974\n",
      "Epoch 421/700\n",
      "2270/2270 [==============================] - 1s 250us/sample - loss: 1.3987 - acc: 0.7097\n",
      "Epoch 422/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 1.3800 - acc: 0.7062\n",
      "Epoch 423/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 1.3954 - acc: 0.7132\n",
      "Epoch 424/700\n",
      "2270/2270 [==============================] - 1s 278us/sample - loss: 1.3680 - acc: 0.7176\n",
      "Epoch 425/700\n",
      "2270/2270 [==============================] - 1s 251us/sample - loss: 1.3574 - acc: 0.7304\n",
      "Epoch 426/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 1.3753 - acc: 0.7093\n",
      "Epoch 427/700\n",
      "2270/2270 [==============================] - 1s 314us/sample - loss: 1.3660 - acc: 0.7194\n",
      "Epoch 428/700\n",
      "2270/2270 [==============================] - 1s 320us/sample - loss: 1.3670 - acc: 0.7088\n",
      "Epoch 429/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.3611 - acc: 0.7203\n",
      "Epoch 430/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.3647 - acc: 0.7106\n",
      "Epoch 431/700\n",
      "2270/2270 [==============================] - 0s 220us/sample - loss: 1.3425 - acc: 0.7225\n",
      "Epoch 432/700\n",
      "2270/2270 [==============================] - 1s 260us/sample - loss: 1.3232 - acc: 0.7304\n",
      "Epoch 433/700\n",
      "2270/2270 [==============================] - 1s 242us/sample - loss: 1.3356 - acc: 0.7176\n",
      "Epoch 434/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.3352 - acc: 0.7185\n",
      "Epoch 435/700\n",
      "2270/2270 [==============================] - 1s 287us/sample - loss: 1.3299 - acc: 0.7176\n",
      "Epoch 436/700\n",
      "2270/2270 [==============================] - 1s 316us/sample - loss: 1.3150 - acc: 0.7330\n",
      "Epoch 437/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.3245 - acc: 0.7344\n",
      "Epoch 438/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.3083 - acc: 0.7264\n",
      "Epoch 439/700\n",
      "2270/2270 [==============================] - 1s 246us/sample - loss: 1.2917 - acc: 0.7278\n",
      "Epoch 440/700\n",
      "2270/2270 [==============================] - 1s 263us/sample - loss: 1.2994 - acc: 0.7233\n",
      "Epoch 441/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 1.3037 - acc: 0.7352\n",
      "Epoch 442/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 1.2998 - acc: 0.7374\n",
      "Epoch 443/700\n",
      "2270/2270 [==============================] - 1s 323us/sample - loss: 1.2877 - acc: 0.7282\n",
      "Epoch 444/700\n",
      "2270/2270 [==============================] - 1s 321us/sample - loss: 1.2715 - acc: 0.7357\n",
      "Epoch 445/700\n",
      "2270/2270 [==============================] - 1s 255us/sample - loss: 1.2820 - acc: 0.7322\n",
      "Epoch 446/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 1.2618 - acc: 0.7361\n",
      "Epoch 447/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 1.2753 - acc: 0.7295\n",
      "Epoch 448/700\n",
      "2270/2270 [==============================] - 1s 280us/sample - loss: 1.2853 - acc: 0.7326\n",
      "Epoch 449/700\n",
      "2270/2270 [==============================] - 1s 246us/sample - loss: 1.2519 - acc: 0.7405\n",
      "Epoch 450/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 1.2565 - acc: 0.7419\n",
      "Epoch 451/700\n",
      "2270/2270 [==============================] - 1s 308us/sample - loss: 1.2464 - acc: 0.7379\n",
      "Epoch 452/700\n",
      "2270/2270 [==============================] - 1s 287us/sample - loss: 1.2605 - acc: 0.7339\n",
      "Epoch 453/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 1.2375 - acc: 0.7432\n",
      "Epoch 454/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 1.2399 - acc: 0.7396\n",
      "Epoch 455/700\n",
      "2270/2270 [==============================] - 1s 243us/sample - loss: 1.2335 - acc: 0.7410\n",
      "Epoch 456/700\n",
      "2270/2270 [==============================] - 1s 262us/sample - loss: 1.2438 - acc: 0.7427\n",
      "Epoch 457/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 1.2482 - acc: 0.7348\n",
      "Epoch 458/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 1.2336 - acc: 0.7427\n",
      "Epoch 459/700\n",
      "2270/2270 [==============================] - 1s 348us/sample - loss: 1.2341 - acc: 0.7436\n",
      "Epoch 460/700\n",
      "2270/2270 [==============================] - 1s 276us/sample - loss: 1.2262 - acc: 0.7449\n",
      "Epoch 461/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 1.2225 - acc: 0.7524\n",
      "Epoch 462/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 1.2004 - acc: 0.7454\n",
      "Epoch 463/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 1.2094 - acc: 0.7467\n",
      "Epoch 464/700\n",
      "2270/2270 [==============================] - 1s 275us/sample - loss: 1.2149 - acc: 0.7392\n",
      "Epoch 465/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.2052 - acc: 0.7546\n",
      "Epoch 466/700\n",
      "2270/2270 [==============================] - 1s 248us/sample - loss: 1.2018 - acc: 0.7537\n",
      "Epoch 467/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 1.1977 - acc: 0.7423\n",
      "Epoch 468/700\n",
      "2270/2270 [==============================] - 1s 343us/sample - loss: 1.1920 - acc: 0.7441\n",
      "Epoch 469/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.1742 - acc: 0.7577\n",
      "Epoch 470/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.1826 - acc: 0.7515\n",
      "Epoch 471/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.1883 - acc: 0.7502\n",
      "Epoch 472/700\n",
      "2270/2270 [==============================] - 1s 323us/sample - loss: 1.1700 - acc: 0.7493\n",
      "Epoch 473/700\n",
      "2270/2270 [==============================] - 1s 266us/sample - loss: 1.1719 - acc: 0.7480\n",
      "Epoch 474/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 1.1788 - acc: 0.7419\n",
      "Epoch 475/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 1.1523 - acc: 0.7608\n",
      "Epoch 476/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 1.1490 - acc: 0.7515\n",
      "Epoch 477/700\n",
      "2270/2270 [==============================] - 1s 252us/sample - loss: 1.1752 - acc: 0.7480\n",
      "Epoch 478/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 1.1697 - acc: 0.7604\n",
      "Epoch 479/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 1.1586 - acc: 0.7573\n",
      "Epoch 480/700\n",
      "2270/2270 [==============================] - 1s 302us/sample - loss: 1.1465 - acc: 0.7634\n",
      "Epoch 481/700\n",
      "2270/2270 [==============================] - 1s 288us/sample - loss: 1.1394 - acc: 0.7586\n",
      "Epoch 482/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 1.1355 - acc: 0.7520\n",
      "Epoch 483/700\n",
      "2270/2270 [==============================] - 0s 220us/sample - loss: 1.1391 - acc: 0.7617\n",
      "Epoch 484/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 1.1299 - acc: 0.7577\n",
      "Epoch 485/700\n",
      "2270/2270 [==============================] - 1s 253us/sample - loss: 1.1314 - acc: 0.7604\n",
      "Epoch 486/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 1.1191 - acc: 0.7634\n",
      "Epoch 487/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.1150 - acc: 0.7643\n",
      "Epoch 488/700\n",
      "2270/2270 [==============================] - 1s 316us/sample - loss: 1.1009 - acc: 0.7696\n",
      "Epoch 489/700\n",
      "2270/2270 [==============================] - 1s 314us/sample - loss: 1.1220 - acc: 0.7581\n",
      "Epoch 490/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.1202 - acc: 0.7529\n",
      "Epoch 491/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.1138 - acc: 0.7630\n",
      "Epoch 492/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 1.1056 - acc: 0.7692\n",
      "Epoch 493/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 1.1074 - acc: 0.7692\n",
      "Epoch 494/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 1.0901 - acc: 0.7683\n",
      "Epoch 495/700\n",
      "2270/2270 [==============================] - 1s 294us/sample - loss: 1.1038 - acc: 0.7656\n",
      "Epoch 496/700\n",
      "2270/2270 [==============================] - 1s 327us/sample - loss: 1.0971 - acc: 0.7665\n",
      "Epoch 497/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.0976 - acc: 0.7705\n",
      "Epoch 498/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.0748 - acc: 0.7692\n",
      "Epoch 499/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.0893 - acc: 0.7709\n",
      "Epoch 500/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 1.0871 - acc: 0.7749\n",
      "Epoch 501/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 1.0686 - acc: 0.7762\n",
      "Epoch 502/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 1.0859 - acc: 0.7753\n",
      "Epoch 503/700\n",
      "2270/2270 [==============================] - 1s 263us/sample - loss: 1.0539 - acc: 0.7806\n",
      "Epoch 504/700\n",
      "2270/2270 [==============================] - 0s 215us/sample - loss: 1.0656 - acc: 0.7740\n",
      "Epoch 505/700\n",
      "2270/2270 [==============================] - 0s 220us/sample - loss: 1.0507 - acc: 0.7837\n",
      "Epoch 506/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 1.0616 - acc: 0.7692\n",
      "Epoch 507/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 1.0541 - acc: 0.7811\n",
      "Epoch 508/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 1.0489 - acc: 0.7692\n",
      "Epoch 509/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 1.0454 - acc: 0.7855\n",
      "Epoch 510/700\n",
      "2270/2270 [==============================] - 1s 292us/sample - loss: 1.0650 - acc: 0.7639\n",
      "Epoch 511/700\n",
      "2270/2270 [==============================] - 1s 298us/sample - loss: 1.0500 - acc: 0.7894\n",
      "Epoch 512/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.0331 - acc: 0.7780\n",
      "Epoch 513/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.0255 - acc: 0.7855\n",
      "Epoch 514/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 1.0276 - acc: 0.7789\n",
      "Epoch 515/700\n",
      "2270/2270 [==============================] - 1s 262us/sample - loss: 1.0182 - acc: 0.7789\n",
      "Epoch 516/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 1.0415 - acc: 0.7811\n",
      "Epoch 517/700\n",
      "2270/2270 [==============================] - 1s 255us/sample - loss: 1.0323 - acc: 0.7771\n",
      "Epoch 518/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 1.0219 - acc: 0.7780\n",
      "Epoch 519/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 1.0197 - acc: 0.7802\n",
      "Epoch 520/700\n",
      "2270/2270 [==============================] - 1s 370us/sample - loss: 1.0137 - acc: 0.7780\n",
      "Epoch 521/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 1.0139 - acc: 0.7811\n",
      "Epoch 522/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 1.0158 - acc: 0.7780\n",
      "Epoch 523/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 1.0157 - acc: 0.7912\n",
      "Epoch 524/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 1.0050 - acc: 0.7872\n",
      "Epoch 525/700\n",
      "2270/2270 [==============================] - 1s 265us/sample - loss: 1.0005 - acc: 0.7938\n",
      "Epoch 526/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 0.9923 - acc: 0.7934\n",
      "Epoch 527/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 1.0062 - acc: 0.7828\n",
      "Epoch 528/700\n",
      "2270/2270 [==============================] - 1s 312us/sample - loss: 0.9859 - acc: 0.7833\n",
      "Epoch 529/700\n",
      "2270/2270 [==============================] - 1s 311us/sample - loss: 0.9797 - acc: 0.7943\n",
      "Epoch 530/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 0.9837 - acc: 0.7885\n",
      "Epoch 531/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 0.9848 - acc: 0.7907\n",
      "Epoch 532/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.9866 - acc: 0.7899\n",
      "Epoch 533/700\n",
      "2270/2270 [==============================] - 1s 252us/sample - loss: 0.9905 - acc: 0.7837\n",
      "Epoch 534/700\n",
      "2270/2270 [==============================] - 1s 262us/sample - loss: 0.9699 - acc: 0.7930\n",
      "Epoch 535/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 0.9814 - acc: 0.7833\n",
      "Epoch 536/700\n",
      "2270/2270 [==============================] - 1s 275us/sample - loss: 0.9662 - acc: 0.7894\n",
      "Epoch 537/700\n",
      "2270/2270 [==============================] - 1s 341us/sample - loss: 0.9797 - acc: 0.7780\n",
      "Epoch 538/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.9483 - acc: 0.8057\n",
      "Epoch 539/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 0.9584 - acc: 0.7956\n",
      "Epoch 540/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 0.9513 - acc: 0.7934\n",
      "Epoch 541/700\n",
      "2270/2270 [==============================] - 1s 261us/sample - loss: 0.9464 - acc: 0.7965\n",
      "Epoch 542/700\n",
      "2270/2270 [==============================] - 1s 278us/sample - loss: 0.9763 - acc: 0.7925\n",
      "Epoch 543/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 0.9397 - acc: 0.7974\n",
      "Epoch 544/700\n",
      "2270/2270 [==============================] - 1s 239us/sample - loss: 0.9451 - acc: 0.7960\n",
      "Epoch 545/700\n",
      "2270/2270 [==============================] - 1s 287us/sample - loss: 0.9582 - acc: 0.7863\n",
      "Epoch 546/700\n",
      "2270/2270 [==============================] - 1s 327us/sample - loss: 0.9434 - acc: 0.7969\n",
      "Epoch 547/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 0.9407 - acc: 0.7903\n",
      "Epoch 548/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.9547 - acc: 0.7921\n",
      "Epoch 549/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.9397 - acc: 0.7965\n",
      "Epoch 550/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 0.9265 - acc: 0.8009\n",
      "Epoch 551/700\n",
      "2270/2270 [==============================] - 1s 266us/sample - loss: 0.9195 - acc: 0.8018\n",
      "Epoch 552/700\n",
      "2270/2270 [==============================] - 0s 220us/sample - loss: 0.9295 - acc: 0.7991\n",
      "Epoch 553/700\n",
      "2270/2270 [==============================] - 1s 234us/sample - loss: 0.9237 - acc: 0.8018\n",
      "Epoch 554/700\n",
      "2270/2270 [==============================] - 1s 318us/sample - loss: 0.9216 - acc: 0.8009\n",
      "Epoch 555/700\n",
      "2270/2270 [==============================] - 1s 306us/sample - loss: 0.9213 - acc: 0.7987\n",
      "Epoch 556/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.9135 - acc: 0.8013\n",
      "Epoch 557/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.9112 - acc: 0.8053\n",
      "Epoch 558/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.9133 - acc: 0.8044\n",
      "Epoch 559/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 0.9001 - acc: 0.8044\n",
      "Epoch 560/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 0.8994 - acc: 0.8048\n",
      "Epoch 561/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.9053 - acc: 0.8031\n",
      "Epoch 562/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.9109 - acc: 0.8018\n",
      "Epoch 563/700\n",
      "2270/2270 [==============================] - 1s 348us/sample - loss: 0.8908 - acc: 0.8128\n",
      "Epoch 564/700\n",
      "2270/2270 [==============================] - 1s 282us/sample - loss: 0.9098 - acc: 0.8035\n",
      "Epoch 565/700\n",
      "2270/2270 [==============================] - 1s 239us/sample - loss: 0.8979 - acc: 0.7996\n",
      "Epoch 566/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 0.8819 - acc: 0.8141\n",
      "Epoch 567/700\n",
      "2270/2270 [==============================] - 1s 231us/sample - loss: 0.8962 - acc: 0.8000\n",
      "Epoch 568/700\n",
      "2270/2270 [==============================] - 1s 267us/sample - loss: 0.8935 - acc: 0.7987\n",
      "Epoch 569/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 0.8810 - acc: 0.8145\n",
      "Epoch 570/700\n",
      "2270/2270 [==============================] - 1s 242us/sample - loss: 0.8969 - acc: 0.8106\n",
      "Epoch 571/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 0.8778 - acc: 0.8115\n",
      "Epoch 572/700\n",
      "2270/2270 [==============================] - 1s 317us/sample - loss: 0.8955 - acc: 0.8097\n",
      "Epoch 573/700\n",
      "2270/2270 [==============================] - 1s 312us/sample - loss: 0.8649 - acc: 0.8128\n",
      "Epoch 574/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 0.8679 - acc: 0.8075\n",
      "Epoch 575/700\n",
      "2270/2270 [==============================] - 1s 289us/sample - loss: 0.8627 - acc: 0.8128\n",
      "Epoch 576/700\n",
      "2270/2270 [==============================] - 1s 356us/sample - loss: 0.8632 - acc: 0.8141\n",
      "Epoch 577/700\n",
      "2270/2270 [==============================] - 1s 243us/sample - loss: 0.8687 - acc: 0.8163\n",
      "Epoch 578/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 0.8678 - acc: 0.8211\n",
      "Epoch 579/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.8679 - acc: 0.8115\n",
      "Epoch 580/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 0.8631 - acc: 0.8132\n",
      "Epoch 581/700\n",
      "2270/2270 [==============================] - 1s 242us/sample - loss: 0.8434 - acc: 0.8242\n",
      "Epoch 582/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.8805 - acc: 0.8167\n",
      "Epoch 583/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 0.8416 - acc: 0.8154\n",
      "Epoch 584/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.8396 - acc: 0.8159\n",
      "Epoch 585/700\n",
      "2270/2270 [==============================] - 1s 245us/sample - loss: 0.8512 - acc: 0.8167\n",
      "Epoch 586/700\n",
      "2270/2270 [==============================] - 1s 233us/sample - loss: 0.8571 - acc: 0.8159\n",
      "Epoch 587/700\n",
      "2270/2270 [==============================] - 1s 266us/sample - loss: 0.8511 - acc: 0.8207\n",
      "Epoch 588/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 0.8507 - acc: 0.8123\n",
      "Epoch 589/700\n",
      "2270/2270 [==============================] - 1s 239us/sample - loss: 0.8500 - acc: 0.8079\n",
      "Epoch 590/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 0.8438 - acc: 0.8097\n",
      "Epoch 591/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 0.8393 - acc: 0.8128\n",
      "Epoch 592/700\n",
      "2270/2270 [==============================] - 0s 204us/sample - loss: 0.8250 - acc: 0.8229\n",
      "Epoch 593/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 0.8277 - acc: 0.8247\n",
      "Epoch 594/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 0.8170 - acc: 0.8282\n",
      "Epoch 595/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 0.8393 - acc: 0.8053\n",
      "Epoch 596/700\n",
      "2270/2270 [==============================] - 0s 212us/sample - loss: 0.8185 - acc: 0.8198\n",
      "Epoch 597/700\n",
      "2270/2270 [==============================] - 0s 199us/sample - loss: 0.8147 - acc: 0.8194\n",
      "Epoch 598/700\n",
      "2270/2270 [==============================] - 0s 205us/sample - loss: 0.8292 - acc: 0.8163\n",
      "Epoch 599/700\n",
      "2270/2270 [==============================] - 0s 187us/sample - loss: 0.8168 - acc: 0.8220\n",
      "Epoch 600/700\n",
      "2270/2270 [==============================] - 0s 190us/sample - loss: 0.8449 - acc: 0.8101\n",
      "Epoch 601/700\n",
      "2270/2270 [==============================] - 0s 185us/sample - loss: 0.8081 - acc: 0.8176\n",
      "Epoch 602/700\n",
      "2270/2270 [==============================] - 0s 211us/sample - loss: 0.8182 - acc: 0.8260\n",
      "Epoch 603/700\n",
      "2270/2270 [==============================] - 0s 202us/sample - loss: 0.8168 - acc: 0.8163\n",
      "Epoch 604/700\n",
      "2270/2270 [==============================] - 1s 312us/sample - loss: 0.8056 - acc: 0.8242\n",
      "Epoch 605/700\n",
      "2270/2270 [==============================] - 1s 259us/sample - loss: 0.8038 - acc: 0.8264\n",
      "Epoch 606/700\n",
      "2270/2270 [==============================] - 0s 215us/sample - loss: 0.8126 - acc: 0.8189\n",
      "Epoch 607/700\n",
      "2270/2270 [==============================] - 1s 225us/sample - loss: 0.8046 - acc: 0.8176\n",
      "Epoch 608/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 0.8160 - acc: 0.8233\n",
      "Epoch 609/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 0.7929 - acc: 0.8247\n",
      "Epoch 610/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 0.8019 - acc: 0.8172\n",
      "Epoch 611/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 0.7864 - acc: 0.8233\n",
      "Epoch 612/700\n",
      "2270/2270 [==============================] - 1s 249us/sample - loss: 0.8146 - acc: 0.8172\n",
      "Epoch 613/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 0.7853 - acc: 0.8278\n",
      "Epoch 614/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 0.7933 - acc: 0.8220\n",
      "Epoch 615/700\n",
      "2270/2270 [==============================] - 1s 340us/sample - loss: 0.7732 - acc: 0.8286\n",
      "Epoch 616/700\n",
      "2270/2270 [==============================] - 1s 253us/sample - loss: 0.7841 - acc: 0.8220\n",
      "Epoch 617/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 0.7911 - acc: 0.8229\n",
      "Epoch 618/700\n",
      "2270/2270 [==============================] - 1s 230us/sample - loss: 0.7938 - acc: 0.8225\n",
      "Epoch 619/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 0.7766 - acc: 0.8278\n",
      "Epoch 620/700\n",
      "2270/2270 [==============================] - 1s 238us/sample - loss: 0.7791 - acc: 0.8247\n",
      "Epoch 621/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 0.7730 - acc: 0.8295\n",
      "Epoch 622/700\n",
      "2270/2270 [==============================] - 1s 258us/sample - loss: 0.7552 - acc: 0.8322\n",
      "Epoch 623/700\n",
      "2270/2270 [==============================] - 1s 343us/sample - loss: 0.7834 - acc: 0.8308\n",
      "Epoch 624/700\n",
      "2270/2270 [==============================] - 1s 243us/sample - loss: 0.7720 - acc: 0.8308\n",
      "Epoch 625/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 0.7715 - acc: 0.8366\n",
      "Epoch 626/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 0.7612 - acc: 0.8313\n",
      "Epoch 627/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270/2270 [==============================] - 0s 213us/sample - loss: 0.7726 - acc: 0.8229\n",
      "Epoch 628/700\n",
      "2270/2270 [==============================] - 0s 204us/sample - loss: 0.7654 - acc: 0.8295\n",
      "Epoch 629/700\n",
      "2270/2270 [==============================] - 0s 207us/sample - loss: 0.7573 - acc: 0.8313\n",
      "Epoch 630/700\n",
      "2270/2270 [==============================] - 0s 209us/sample - loss: 0.7664 - acc: 0.8264\n",
      "Epoch 631/700\n",
      "2270/2270 [==============================] - 1s 259us/sample - loss: 0.7582 - acc: 0.8344\n",
      "Epoch 632/700\n",
      "2270/2270 [==============================] - 0s 209us/sample - loss: 0.7669 - acc: 0.8264\n",
      "Epoch 633/700\n",
      "2270/2270 [==============================] - 0s 206us/sample - loss: 0.7584 - acc: 0.8251\n",
      "Epoch 634/700\n",
      "2270/2270 [==============================] - 1s 246us/sample - loss: 0.7638 - acc: 0.8295\n",
      "Epoch 635/700\n",
      "2270/2270 [==============================] - 1s 354us/sample - loss: 0.7937 - acc: 0.8264\n",
      "Epoch 636/700\n",
      "2270/2270 [==============================] - 1s 221us/sample - loss: 0.7788 - acc: 0.8313\n",
      "Epoch 637/700\n",
      "2270/2270 [==============================] - 0s 214us/sample - loss: 0.8012 - acc: 0.8189\n",
      "Epoch 638/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 0.7900 - acc: 0.8238\n",
      "Epoch 639/700\n",
      "2270/2270 [==============================] - 1s 227us/sample - loss: 0.7915 - acc: 0.8278\n",
      "Epoch 640/700\n",
      "2270/2270 [==============================] - 1s 264us/sample - loss: 0.7747 - acc: 0.8291\n",
      "Epoch 641/700\n",
      "2270/2270 [==============================] - 1s 244us/sample - loss: 0.7872 - acc: 0.8247\n",
      "Epoch 642/700\n",
      "2270/2270 [==============================] - 1s 240us/sample - loss: 0.7772 - acc: 0.8233\n",
      "Epoch 643/700\n",
      "2270/2270 [==============================] - 1s 307us/sample - loss: 0.7541 - acc: 0.8313\n",
      "Epoch 644/700\n",
      "2270/2270 [==============================] - 1s 300us/sample - loss: 0.7617 - acc: 0.8264\n",
      "Epoch 645/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 0.7580 - acc: 0.8278\n",
      "Epoch 646/700\n",
      "2270/2270 [==============================] - 1s 226us/sample - loss: 0.7478 - acc: 0.8396\n",
      "Epoch 647/700\n",
      "2270/2270 [==============================] - 0s 217us/sample - loss: 0.7422 - acc: 0.8370\n",
      "Epoch 648/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 0.7518 - acc: 0.8242\n",
      "Epoch 649/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 0.7255 - acc: 0.8471\n",
      "Epoch 650/700\n",
      "2270/2270 [==============================] - 1s 257us/sample - loss: 0.7512 - acc: 0.8344\n",
      "Epoch 651/700\n",
      "2270/2270 [==============================] - 1s 220us/sample - loss: 0.7206 - acc: 0.8502\n",
      "Epoch 652/700\n",
      "2270/2270 [==============================] - 1s 246us/sample - loss: 0.7248 - acc: 0.8463\n",
      "Epoch 653/700\n",
      "2270/2270 [==============================] - 1s 247us/sample - loss: 0.7387 - acc: 0.8322\n",
      "Epoch 654/700\n",
      "2270/2270 [==============================] - 1s 304us/sample - loss: 0.7351 - acc: 0.8300\n",
      "Epoch 655/700\n",
      "2270/2270 [==============================] - 1s 303us/sample - loss: 0.7269 - acc: 0.8379\n",
      "Epoch 656/700\n",
      "2270/2270 [==============================] - 1s 223us/sample - loss: 0.7225 - acc: 0.8436\n",
      "Epoch 657/700\n",
      "2270/2270 [==============================] - 0s 216us/sample - loss: 0.7231 - acc: 0.8419\n",
      "Epoch 658/700\n",
      "2270/2270 [==============================] - 1s 224us/sample - loss: 0.7222 - acc: 0.8339\n",
      "Epoch 659/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 0.7189 - acc: 0.8463\n",
      "Epoch 660/700\n",
      "2270/2270 [==============================] - 1s 254us/sample - loss: 0.7016 - acc: 0.8471\n",
      "Epoch 661/700\n",
      "2270/2270 [==============================] - 1s 237us/sample - loss: 0.7202 - acc: 0.8352\n",
      "Epoch 662/700\n",
      "2270/2270 [==============================] - 1s 228us/sample - loss: 0.7004 - acc: 0.8436\n",
      "Epoch 663/700\n",
      "2270/2270 [==============================] - 1s 338us/sample - loss: 0.7084 - acc: 0.8449\n",
      "Epoch 664/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.7071 - acc: 0.8361\n",
      "Epoch 665/700\n",
      "2270/2270 [==============================] - 0s 206us/sample - loss: 0.7111 - acc: 0.8330\n",
      "Epoch 666/700\n",
      "2270/2270 [==============================] - 1s 246us/sample - loss: 0.7220 - acc: 0.8352\n",
      "Epoch 667/700\n",
      "2270/2270 [==============================] - 1s 236us/sample - loss: 0.7060 - acc: 0.8458\n",
      "Epoch 668/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 0.6913 - acc: 0.8445\n",
      "Epoch 669/700\n",
      "2270/2270 [==============================] - 1s 391us/sample - loss: 0.6947 - acc: 0.8401\n",
      "Epoch 670/700\n",
      "2270/2270 [==============================] - 1s 308us/sample - loss: 0.7323 - acc: 0.8304\n",
      "Epoch 671/700\n",
      "2270/2270 [==============================] - 0s 208us/sample - loss: 0.6984 - acc: 0.8449\n",
      "Epoch 672/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 0.6929 - acc: 0.8379\n",
      "Epoch 673/700\n",
      "2270/2270 [==============================] - 0s 203us/sample - loss: 0.6947 - acc: 0.8383\n",
      "Epoch 674/700\n",
      "2270/2270 [==============================] - 0s 197us/sample - loss: 0.6839 - acc: 0.8498\n",
      "Epoch 675/700\n",
      "2270/2270 [==============================] - 0s 197us/sample - loss: 0.7048 - acc: 0.8419\n",
      "Epoch 676/700\n",
      "2270/2270 [==============================] - 0s 202us/sample - loss: 0.6858 - acc: 0.8445\n",
      "Epoch 677/700\n",
      "2270/2270 [==============================] - 0s 208us/sample - loss: 0.6986 - acc: 0.8423\n",
      "Epoch 678/700\n",
      "2270/2270 [==============================] - 1s 241us/sample - loss: 0.6934 - acc: 0.8405\n",
      "Epoch 679/700\n",
      "2270/2270 [==============================] - 0s 210us/sample - loss: 0.6814 - acc: 0.8489\n",
      "Epoch 680/700\n",
      "2270/2270 [==============================] - 1s 267us/sample - loss: 0.6963 - acc: 0.8414\n",
      "Epoch 681/700\n",
      "2270/2270 [==============================] - 1s 314us/sample - loss: 0.6884 - acc: 0.8445\n",
      "Epoch 682/700\n",
      "2270/2270 [==============================] - 0s 213us/sample - loss: 0.6945 - acc: 0.8449\n",
      "Epoch 683/700\n",
      "2270/2270 [==============================] - 0s 214us/sample - loss: 0.6791 - acc: 0.8493\n",
      "Epoch 684/700\n",
      "2270/2270 [==============================] - 0s 209us/sample - loss: 0.6888 - acc: 0.8370\n",
      "Epoch 685/700\n",
      "2270/2270 [==============================] - 1s 235us/sample - loss: 0.6763 - acc: 0.8445\n",
      "Epoch 686/700\n",
      "2270/2270 [==============================] - 0s 218us/sample - loss: 0.6724 - acc: 0.8480\n",
      "Epoch 687/700\n",
      "2270/2270 [==============================] - 0s 219us/sample - loss: 0.6797 - acc: 0.8427\n",
      "Epoch 688/700\n",
      "2270/2270 [==============================] - 1s 269us/sample - loss: 0.6567 - acc: 0.8533\n",
      "Epoch 689/700\n",
      "2270/2270 [==============================] - 1s 313us/sample - loss: 0.6687 - acc: 0.8498\n",
      "Epoch 690/700\n",
      "2270/2270 [==============================] - 0s 209us/sample - loss: 0.6673 - acc: 0.8524\n",
      "Epoch 691/700\n",
      "2270/2270 [==============================] - 0s 208us/sample - loss: 0.6626 - acc: 0.8581\n",
      "Epoch 692/700\n",
      "2270/2270 [==============================] - 0s 203us/sample - loss: 0.6647 - acc: 0.8467\n",
      "Epoch 693/700\n",
      "2270/2270 [==============================] - 1s 251us/sample - loss: 0.6641 - acc: 0.8529\n",
      "Epoch 694/700\n",
      "2270/2270 [==============================] - 1s 229us/sample - loss: 0.6628 - acc: 0.8485\n",
      "Epoch 695/700\n",
      "2270/2270 [==============================] - 1s 232us/sample - loss: 0.6605 - acc: 0.8489\n",
      "Epoch 696/700\n",
      "2270/2270 [==============================] - 1s 336us/sample - loss: 0.6668 - acc: 0.8414\n",
      "Epoch 697/700\n",
      "2270/2270 [==============================] - 0s 210us/sample - loss: 0.6603 - acc: 0.8599\n",
      "Epoch 698/700\n",
      "2270/2270 [==============================] - 0s 214us/sample - loss: 0.6557 - acc: 0.8533\n",
      "Epoch 699/700\n",
      "2270/2270 [==============================] - 0s 212us/sample - loss: 0.6605 - acc: 0.8524\n",
      "Epoch 700/700\n",
      "2270/2270 [==============================] - 1s 222us/sample - loss: 0.6547 - acc: 0.8449\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model_obj.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack last missing piece for the jigsaw puzzle i've been working on\n",
      "Shrek and man pounded by the handsome physically manifested sound that some people hear\n",
      "Mothman wizard harriet also a lesbian and she eats me right\n",
      "My librarian is a beautiful lesbian ice cream cone\n"
     ]
    }
   ],
   "source": [
    "class Prediction():\n",
    "    def __init__(self,tokenizer,max_len):\n",
    "        self.model = None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_len\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model = tf.keras.models.load_model(\"lang_model.h5\")\n",
    "\n",
    "    def predict_sequnce(self, text, num_words_gen):\n",
    "        for id in range(num_words_gen):\n",
    "            # convert input text to tokenized and padded sequence\n",
    "            encoded_data = self.tokenizer.texts_to_sequences([text])[0]\n",
    "            padded_data = tf.keras.preprocessing.sequence.pad_sequences([encoded_data],maxlen = self.max_length-1,padding='pre')\n",
    "            # predict next word\n",
    "            y_pred = self.model.predict(padded_data)\n",
    "            y_pred = np.argmax(y_pred)\n",
    "            # convert prediction to word using index_word in tokenizer\n",
    "            predict_word = self.tokenizer.index_word[y_pred]\n",
    "            # append predicted word to existing text\n",
    "            text += ' ' + predict_word\n",
    "        return text\n",
    "    \n",
    "\n",
    "pred = Prediction(data.tokenizer, data.max_len)  \n",
    "pred.model = model_obj.model\n",
    "print(pred.predict_sequnce(\"Jack\", 11))\n",
    "print(pred.predict_sequnce('Shrek and', 12))\n",
    "print(pred.predict_sequnce('Mothman', 10))\n",
    "print(pred.predict_sequnce('My', 8))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
